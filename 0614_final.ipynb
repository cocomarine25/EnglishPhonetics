{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocomarine25/EnglishPhonetics/blob/main/0614_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <0510>"
      ],
      "metadata": {
        "id": "v0dO8UcprKDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "meta의 Liama : LLM 모델\n",
        "\n",
        "이전 시간에 어떤 것이 말해졌다면(하나든 서른개든) 그 다음 단어를 알게 된다면 하나하나 물어서 끝까지 알 수 있게 됨\n",
        "\n",
        "next word\n",
        "\n",
        "transformer\n",
        "\n",
        "Attention is all you need(논문) - 구글의 논문이지만 실제로 수익을 창출하고 있는 것은 MS의 open AI의 chatGPT, 인기를 끌고 있는 것은 meta의 liama이다.\n",
        "\n",
        "** input --> function --> output **\n",
        "\n",
        "** input --> AI --> output **\n",
        "\n",
        "vector는 한 줄 짜리 숫자(당연히 순서가 있음) ex) -1, 2, 0, 6, 0\n",
        "\n",
        "입력벡터 --> metrix --> 출력벡터 : 이 그림이 머릿속에 들어와 있어야함\n",
        "\n",
        "텐서까지는 몰라도 되지만 matrix, vertor, scalar는 알아야 함\n",
        "\n",
        "행렬이 여러개 있으면 어떻게 해야하나? --> 처음 4개 곱하기 3X4\n",
        "\n",
        "deep learning이라는 것은 행렬이 많다는 것을 말한다.(깊은거 아님) 챗지피티는 행렬이 25000개 정도 된다고 함.\n",
        "\n",
        "딥러닝이라는 말이 나온 지 얼마 되지 않음\n",
        "\n",
        "STT : speech to text\n",
        "\n",
        "openAI의 whisper 등\n",
        "\n",
        "TTS : text to speech\n",
        "\n",
        "안녕하세요 라이나생명 상담원 나영은입니다. 요즘 치아 건강은 어떠세요? 같은거\n",
        "\n",
        "오픈AI가 Dall E 3라는 이미지, whisper 음성, chatGPT 텍스트 모든 면에서 최고다.\n",
        "\n",
        "엔비디아의 그래픽카드로 AI가 돌아감\n",
        "\n",
        "그래서 엔비디아와 MS가 시총 1, 2위를 겨룸"
      ],
      "metadata": {
        "id": "yj-fqJQaqukS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# linear 2"
      ],
      "metadata": {
        "id": "a9wNV8G_rVs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일단 지난 중간고사가 변별력이 별로 없어서 이번 기말고사는 어렵게 낼 것이다(20문제, 모두 고르시오)\n",
        "\n",
        "오늘 수업에서 시험 문제가 많이 나올 것이다.\n",
        "\n",
        "Ax = b(Ax --> b)이 공식에 익숙해져야 한다.\n",
        "\n",
        "소문자는 벡터, 대문자는 행렬, x는 입력벡터, b는 출력벡터\n",
        "\n",
        "AI에서 Ax부분은 함수이다.\n",
        "\n",
        "A부분이 반드시 직사각형 일 필요는 없지만 5X3(가로3, 세로5인 직사각형) X 3X1(가로1, 세로3인 직사각형 = 5X1(가로1 세로 5인 직사각형)\n",
        "\n",
        "3X1은 3차원에 존재함\n",
        "\n",
        "5X1은 5차원에 존재함\n",
        "\n",
        "행렬 자체를 차원을 넘나든다고 말할 수 있음. A라는 행렬이 3차원 상에 있는 벡터를 5차원상에 있는 출력벡터로 바꿔줌\n",
        "\n",
        "만약 A가 5X5라면 같은 차원에서 같은 차원으로 보내는 것이다.\n",
        "\n",
        "이 A를 linear(곱하기, 더하기 밖에 없는 것) transformation을 하는 것이다."
      ],
      "metadata": {
        "id": "sA8NJ2rHquh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예1)"
      ],
      "metadata": {
        "id": "np5t546_qufU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "|0.9  -0.4|   | 1 |   |0.5|\n",
        "|0.4  0.9 |   | 1 |   |1.3|"
      ],
      "metadata": {
        "id": "LGfRbD0sriI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 1  0 |\n",
        "\n",
        "| 0  1 |\n",
        "\n",
        "이 행렬은 x, y가 (1,0)과 (0,1)인 두개의 벡터로 생각할 수 있다.(세로 순서로 봐야됨)\n",
        "\n",
        "이것이 가장 기본 행렬이다.\n",
        "\n",
        "original grid이다."
      ],
      "metadata": {
        "id": "kbj92vGKquct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|0.9  -0.4|\n",
        "\n",
        "|0.4  0.9 |\n",
        "\n",
        "이 행렬은 뒤에 1이랑0으로 이루어진 행렬이 기울어진 느낌이다.\n",
        "\n",
        "x, y가 (0.9, 0.4)랑 (-0.4, 0.9)로 이루어져 있다.\n",
        "\n",
        "transformation grid이다."
      ],
      "metadata": {
        "id": "EFtfG3VDquaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 1 |\n",
        "\n",
        "| 1 |\n",
        "\n",
        "이 점이\n",
        "\n",
        "| 0.5 |\n",
        "\n",
        "| 1.3 |\n",
        "\n",
        "의 점이 되는 것이 예1)이다.\n",
        "\n",
        "원래의 그리드에서 (1, 1)이 새로운 그리드 상에서 (0.5, 1.3)인 것이다."
      ],
      "metadata": {
        "id": "0QxBf5dxquXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# detransformation : Inverse matrix"
      ],
      "metadata": {
        "id": "v0rJYgz8quUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "역함수\n",
        "\n",
        "A^-1b = x\n"
      ],
      "metadata": {
        "id": "_Ze0WULvquH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예2)"
      ],
      "metadata": {
        "id": "NRgt7GIqrrlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "|0.9  -0.4|^-1   | 1 |   |0.5|\n",
        "|0.4  0.9 |      | 1 |   |1.3|"
      ],
      "metadata": {
        "id": "FCwBBwj-rwuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본은 오리지날에서 변형된 그리드로 바꾸는 것이지만 역행렬은 (역행렬되기전, 0.9랑 0.4 있는 부분)을 오리지날로 바꾸는 것이다.\n",
        "\n",
        "그래서 (0.5, 1.3)을 (1, 1)로 돌려주는 것\n"
      ],
      "metadata": {
        "id": "sBwtZk7Qrri4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예3)"
      ],
      "metadata": {
        "id": "0onOlvd_rrdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 변형된 그리드가 1차원의 선 형태의 벡터라면(두 개의 벡터가 같은 선상에 있다면) 역행렬이 존재하지 않는다.\n",
        "\n"
      ],
      "metadata": {
        "id": "tvLc1529rrbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "따라서 두 벡터가 만들어내는 평행사변형의 면적이 0이 아니라면 역행렬이 존재한다. 라고 정의한다.\n",
        "\n",
        "역행렬이 존재하는지 아닌지를 행렬에서는 determinant라고 한다.\n",
        "\n",
        "determinant가 0이면 역행렬이 존재하지 않는 것이다.\n",
        "\n",
        "| a  b |\n",
        "\n",
        "| c  d |\n",
        "\n",
        "이렇게 있다면 a곱하기d - b곱하기c를 한 것이 평행사변형의 면적이므로 0이 아니면 된다."
      ],
      "metadata": {
        "id": "4bzMZ9RRr3GN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# eigenvector\n"
      ],
      "metadata": {
        "id": "0c4Z0kWCr3Dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형 계수(?)에서 중요한 두 가지는 위에서 설명한 트렌스 벡터랑 아이겐 벡터(중요함)다."
      ],
      "metadata": {
        "id": "ms4-wxtYr3BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Av=b\n",
        "\n",
        "A transforms v to b\n",
        "\n",
        "|1.25 0.25|  |1|  = | 1.5 |\n",
        "\n",
        "|  0.25    1 |  |1|    |1.25 |\n",
        "\n",
        "위의 식은 처음 정사각형을 찌부시켜서 평행사변형으로 만드는 것이라고 생각하면 된다.\n",
        "\n",
        "아이겐 벡터는 기본 메트릭스에서 어떤 입력벡터 A는 출력벡터 b와 일직선에 놓이는 벡터는 2개가 존재한다는 것이다. (2X2라 두개이고, 3X3은 3개, 4X4는 4개다.)\n",
        "\n",
        "다시말해서 원점과 v와 Av가 일직선상에 놓이게 하는 v를 아이겐 벡터라고 한다. 위의 식에서 아이겐벡터는 2개가 존재한다.\n",
        "\n",
        "사실 아이겐 벡터의 수치상의 개수는 무한대이며 방향은 2개다.(하지만 아이겐 벡터는 2개라고 이야기하는게 맞다.)\n",
        "\n",
        "실제로 원점으로부터 반지름이 1이 되는 단위원을 그리고 그 지점과 만나는 두 점을 아이겐 벡터라고 한다.\n",
        "\n",
        "그리고 이 두개의 아이겐 벡터는 반드시 직각을 이룬다.\n",
        "\n",
        "처음 A행렬(영어, 국어, 수학, 과학)을 90도로 이루어진 두 행렬로 표현하고자 한것(언어, 수리) 이게 중요하다고 함"
      ],
      "metadata": {
        "id": "IrpN_256r2_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "eigenvalues는 일직선상(아이겐 벡터 상)에 놓았을 때 0부터 Av까지의 거리를 말한다.\n",
        "\n",
        "이게 어떤 뜻이냐면 두 벡터사이의 비율인데, v를 단위원에 맞춰서 1이라고 하면 Av는 1.x가 나올 것이고 1:1.x의 비율이 된다."
      ],
      "metadata": {
        "id": "n2ZjFd-fr28s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "0zTXTTmP-Dxb"
      },
      "source": [
        "# 시험 전 마지막 수업"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<기본 목차>\n",
        "\n",
        "Linear algebra\n",
        "\n",
        "뉴런 네트워크\n",
        "\n",
        "기본적인 llm(메모리가 가장 문제가 된다.) - 8빌리언 파라미터(행렬의 내부 숫자)라면 메모리가 얼마나 필요한가?)\n",
        "\n",
        "프리시즌\n",
        "\n",
        "허깅페이스에서 모델 불러와서 해보는거(llm이 프리트레이닝으로 훈련하는 것과 파인 튜닝으로 훈련하는 것이 다르다.) 그리고 쓰는 것\n",
        "\n",
        "leg가 무엇인지"
      ],
      "metadata": {
        "id": "-YRmQy4sS_Oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data_AI.pdf\n",
        "\n",
        "벡터는 입력벡터, 행렬, 출력벡터\n",
        "행렬은 여러개일 수 있다.\n",
        "\n",
        "챗gpt는 175B파라미터(1750억)\n",
        "\n",
        "AI행렬은 function\n",
        "\n",
        "LM은 랭기지 모델\n",
        "\n",
        "STT는 음성인식 speech to text\n",
        "\n",
        "이미지 recognize\n",
        "\n",
        "이미지 generation\n",
        "\n",
        "LLM이 좋은건 레이턴시가 작고, ... 등\n",
        "\n",
        "여기까지는 기본이라 다들 알고있어야함"
      ],
      "metadata": {
        "id": "DoAjV0AkTgTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Net basics.pdf\n",
        "\n",
        "입력이 하나, 출력이 하나인 경우에 가장 작다.\n",
        "\n",
        "예를들어 커피를 얼마나 마셨는지에 따라 사람의 수면 시간을 예상할 수 있다.(입력 : 커피 몇잔?, 출력 : 수면 시간)\n",
        "\n",
        "y=ax+b에서 a와b값을 구하는 것이 AI다.\n",
        "\n",
        "ANN DNN그림에서 X는 입력, 화살표는 행렬, 그 다음hidden_1은 중간벡터 --> 마지막 벡터가 출력\n",
        "\n",
        "경제학이나 경영학의 회귀분석이 AI에 사용된다.\n",
        "\n",
        "다차원의 벡터가 다차원의 벡터로 가는 것을 ANN DNN이라고 한다.\n",
        "\n",
        "시험문제에 그림을 띄울 수도 있다.(설명한 부분만)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lJ_nVZv1UylG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN이 우리가 하는 것이다.(시간적인 부분)\n",
        "\n",
        "RNN은 해석을 잘 해야하는데\n",
        "\n",
        "첫번째 RNN ppt는 동그라미 하나지만 그 안에 여러개의 벡터가 있다고 생각하면 된다. 말 그대로 위의 ANN DNN그림에서 Wh0, Whh, Wih가 포함되어 있는 것이다.(이전의 중간벡터와 현재의 중간벡터를 연결해주는 화살 벡터가 있다.)\n",
        "\n",
        "T1을 위한 행렬 T2를 위한 행렬이 필요 없이 벡터 하나로 바뀐 것이다.\n",
        "\n",
        "그러니까 RNN 오른쪽 그림을 보면 순서가 아래 위, 다시 아래 위, 다시 아래 위 이렇게 된다.\n",
        "\n",
        "데이터를 이용해서 화살표를 업데이트하는 것을 훈련이라고 하고,\n",
        "\n",
        "실제로 '나는'을 입력하면 '오늘'이 나와야하는데 다른 것이 나오면 그것이 loss이다. 이 loss가 Wih, Whh, Who로 들어간다. 이것이 훈련이다.\n",
        "\n",
        "\n",
        "\n",
        "예를 들어 2020년 주식값을 x1에 넣으면, 그 값이 y1로 나오게 된다. 이렇게 하더라도 한국어에서 영어로 번역을 할 때 입력 길이와 출력 길이와 다르거나 1대1 매치가 되지 않는다면 문제가 생기기도 한다."
      ],
      "metadata": {
        "id": "_mNN7c-gYltD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래서 생긴 것이 시퀀스 투 시퀀스다.\n",
        "\n",
        "seq2seq\n",
        "\n",
        "여기에서 트렌스포머라는 개념이 나온다.\n",
        "\n",
        "트랜스포머는 동시에 하는 것이다. x1, x2, x3의 값을 동시에 구한다.\n",
        "\n",
        "그 다음 구해진 값을 모두 곱한다?(sum이긴 함)\n",
        "\n",
        "다시 말해 go의 값을 구하려면 나는, 집에, 간다 중에서 가장 영향력을 많이 미친 간다 부분이 go로 오게 되는 것이다.\n",
        "\n",
        "앞부분을 인코드 대충 sos쪽부터 뒷부분을 디코드라고 하는데 챗지피티는 디코드를 사용한다.\n",
        "\n",
        "훈련하는 방법은 데이터의 정제도 필요 없이 아무 문장이나 집에넣으면 되는 것이다.\n",
        "\n",
        "순서대로 추측이 되게 한다. sos(문장 처음)이 I라면 그 다음은 go가 오고 그 다음은 home이 온다.\n",
        "\n",
        "이것이 프리트레이닝이다. llm의 프리트레이닝은 문장을 계속 넣으면서 그 다음 단어를 예측하면된다. 예측하기 이전에 나왔던 모든 것을 파악하고 있으면서 해야한다. i don't like to 다음에 뭐가 나온다는 것을 알아야지, 그냥 to 다음에 뭐가 나온다는 것만 알면 안된다.\n",
        "\n",
        "80억개 이상은 있어야 틀리지 않는다. 근데 말이 틀리지 않는 거랑 정보를 제대로 주는 것은 다르다.\n",
        "\n",
        "트레이닝은 pretraing(문장만 있으면 됨)이 있고 fine training(문장이 QA의 형태로 세팅되어야 함)이 있다.\n",
        "\n",
        "문장을 QA 형식으로 pretraing처럼 계속 돌리면 그것이 파인 트레이닝인 것이다."
      ],
      "metadata": {
        "id": "JFQ37GMuYtWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# basicterms.pdf\n",
        "\n",
        "- CPU는 6코어(계산할 수 있는 주체가 6개 있는 것)\n",
        "\n",
        "스티브잡스같은 천재\n",
        "\n",
        "- 지포스 RTX에서 24GB부분이 중요함(스트림 프로세서 16384가 머리수다)\n",
        "\n",
        "곱하기 더하기만 하는 초등학생\n",
        "\n",
        "- Llama3의 개수는 params의 크기다. 8B는 참치같은 것 70B는 고래같은것. 그래서 요리하기 위해서 큰 도마가 필요하다.\n",
        "\n",
        "이걸 계산하는 방법이 다음 장에 MAX, min이다.\n",
        "\n",
        "32비트는 01하는 것을 32개를 쓰는 것\n",
        "\n",
        "70B에서 B는 0을 9개 더 추가해야 됨.(70B는 700억)\n",
        "\n",
        "280,000,000,000 bytes(2800억 바이트)\n",
        "\n",
        "= 280,000 Mbytes(28만 메가바이트)\n",
        "\n",
        "= 280 Gbytes(280 기가바이트)\n",
        "\n",
        "GPU memory for training? 훈련할 때는 3~5배 이상의 메모리가 필요하다.\n",
        "\n",
        "memory for inference? 그냥 사용할 때는 그대로 메모리가 필요하다.\n",
        "\n",
        "그 아래 float32 그림은 시험에 안나옴.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_oVNXeR1bye-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear algebra\n",
        "# LA_2024Spring.pdf"
      ],
      "metadata": {
        "id": "eRmbn4BsvPlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "벡터는 한줄짜리 숫자다.\n",
        "\n",
        "표현은 기하적으로 가능하다.(그래프 그릴 수 있다는 뜻)\n",
        "\n",
        "기하적으로 할 떄는 칼럼 벡타, 로우 벡타 상관 없다.\n",
        "\n",
        "multoplication : 곱하면 두배가 된다.\n",
        "\n",
        "addition : 더하면 합 만큼 된다.\n",
        "\n",
        "\n",
        "\n",
        "[6, -2, 4], [-1, 0, 2] : 벡터 한 점과 다른 벡터 한 점과 원점이 이루는 것은 평면에 있다. = 맞는 말이다.(3차원이든 10차원이든 맞다.)\n",
        "\n",
        "3차원 벡터 하나랑 원점이랑 이루는 것은 1차원이다. 직선이니까\n",
        "\n",
        "3차원 벡터 3개랑 원점이랑 이루는 것은 3차원이다.\n",
        "\n",
        "3차원 벡터 2개랑 원점이 1차원을 이루려면 3차원 벡터 2개가 일직선에 위치하면 되는 것이다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0V12p5HhdJMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** inner product - 이번 학기에 가장 중요함 **\n",
        "\n",
        "[2, 3]은 1 by 2다.\n",
        "a와 b는 곱해지지 않는다.\n",
        "1x2랑 1x2는 곱해지지 않는다. 1xn, nx1이렇게 같은 부분이 만나야 곱할 수 있다.\n",
        "\n",
        "그래서 이렇게 곱할 수 있도록 만드는 과정이 algebraic이다.\n",
        "\n",
        "그래서 axb 이렇게 쓰면 틀린 것이다. a와 b는 둘다 1x2이기 때문이다. 그래서 a.b 이렇게 표현해야 한다.\n",
        "\n",
        "두 벡터를 이너프로덕트 한다는 말은 기하적으로 두 벡터가 있고, 원점이 있는데 한 벡터를 다른 벡터쪽으로 수직으로 내리는 것이다.\n",
        "\n",
        "그게 |a||b|cos()이다. 그리고 이게 geometric이다.\n",
        "\n",
        "기본적으로 벡터는 AI에 들어가는 입출력이고, 인포메이션이다.\n",
        "\n",
        "두 벡터간의 유사도는 각도만 사용한다.(cosine())\n",
        "\n",
        "유사도는 -1 ~ 1까지고 0이 가장 유사하지 않은 것이다. -1은 반비례다.\n",
        "\n",
        "a와b의 거리를 유클리디언 디스턴스라고 한다.\n",
        "\n",
        "10차원에서도 차이를 제곱해서 더하고 루트를 씌우면 된다.\n",
        "\n",
        "- correlation은 한 선을 기준으로 선에 많은 점이 붙어있으면 값이 높다고 한다. science가 1에 더 가까운 것\n",
        "\n",
        "- 가장 중요한 것은 correlation = cosine\n",
        "\n",
        "과학 점수와 수학 점수를 모아서 점을 찍을 수 있다.\n",
        "\n",
        "통계 프로그램에 넣지 않고 하나하나씩 해서 R값을 구할 수 있다.\n",
        "\n",
        "inner product signal vectors : 같은 벡터의 inner product는 값이 매우 클 것이다.\n",
        "\n",
        "a와 b는 9차원이다. a.b의 cos는? 1이다. a의 모든 값을 각각 제곱하고, b의 모든 값을 각각 제곱하고, 두 절댓값을 곱하고, cos값을 곱함.\n",
        "\n",
        "두 곡선이 90도 만큼 차이가 나면 inner product는 0값이 된다."
      ],
      "metadata": {
        "id": "Cqf1nO_KeUXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear algebra II\n",
        "# LA_2024SpringII.pdf"
      ],
      "metadata": {
        "id": "5bwsGth4y5Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ax = b : 트랜스포메이션 메트릭스라고 함**\n",
        "\n",
        "대문자가 행렬, 소문자가 벡터\n",
        "\n",
        "x가 입력, b가 출력\n",
        "\n",
        "여기에서 기하가 정말 중요하다.\n",
        "\n",
        "이 부분은 저번시간에 내가 메모 열심히 했음!\n",
        "\n",
        "대충 벡터의 방향을 바꾸는 것이 transformation이 하는 일이다.\n",
        "\n",
        "이걸 사용하는 예시 = 사진 상하좌우 바꾸기\n",
        "\n",
        "트랜스포메이션 행렬을 곱하면 됨.\n",
        "\n",
        "일직선상으로 바뀐 트렌스포메이션은 어떠한 값을 곱하더라도 1차원을 벗어날 수 없다.\n",
        "\n",
        "**A^-1b=x : 역행렬**\n",
        "\n",
        "트랜스포메이션을 거꾸로 하는 것\n",
        "\n",
        "일직선상이라면 역행렬이 존재하지 않는다.\n",
        "\n",
        "determinent는 면적이다.\n",
        "\n",
        "|1 2|\n",
        "\n",
        "|1 2|\n",
        "\n",
        "이건 0임. (아래 1)x(아래 2) - (위에 2)x(아래 1)하면 0이기 떄문이다.\n",
        "\n",
        "면적이 0이면 그것은 일직선 상인거임. ex)1111\n",
        "\n"
      ],
      "metadata": {
        "id": "YiQrnp20ix0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 eigenvector가 중요하다 했다고 했음.\n",
        "\n",
        "정사각형을 가진 행렬이 있을 때 가능하다.\n",
        "\n",
        "Av=b랑 Ax=b랑 같은거다.\n",
        "\n",
        "아이겐 벡터는 2x2에서는 2개가 나오고 3x3에서는 3개가 나온다.\n",
        "\n",
        "transform한 결과의 벡터가 원점과 일직선이 되는 벡터가 eigenvector이다.\n",
        "\n",
        "아이겐 벡터 = 고유 벡터(그 방향 자체를 의미함)\n",
        "\n",
        "아이겐 벡터의 직각도 아이겐 벡터임(즉, 2개가 존재함)\n",
        "\n",
        "대표 아이겐 벡터는 원점으로 부터 기준원을 그리고 그 지점을 지나는 점을 아이겐 벡터라고 하기도 한다. 수치상으로는 무한대의 개수가 존재하긴 한다.\n",
        "\n",
        "모든 가능한 v에서 몇개의 v는 아이겐 벡터로 간다.\n",
        "\n",
        "Av = ㅅv\n",
        "\n",
        "v : eigenvectors\n",
        "\n",
        "ㅅ : eigenvalues\n",
        "\n",
        "아이겐 벡터는 방향, 아이겐 벨류는 값(숫자)\n",
        "\n",
        "링크 사이트에 들어가면 직접 해볼 수 있음.\n",
        "\n",
        "3차원에서도 벡터가 3개 있을 뿐이지 아이겐 벡터는 존재한다. 근데 서로 수직인 3개의 아이겐 벡터가 나올 것이다.\n",
        "\n",
        "아이겐 벡터가 수직으로 표현이 된다는 것은 서로 상관이 없는 것(영어 능력과 언어 능력을 한번에 같이)\n"
      ],
      "metadata": {
        "id": "DUKa00JFmh1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 리뷰를 하지 않았다고 나오지 않는 것은 아니다."
      ],
      "metadata": {
        "id": "ZGZt0A5Vpx74"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}